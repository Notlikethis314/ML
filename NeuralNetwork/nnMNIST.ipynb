{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing NN using MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 17879934.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 2133421.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 10880338.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=16, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X, y\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X, y\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.881491  [   64/60000]\n",
      "loss: 1.831724  [ 6464/60000]\n",
      "loss: 1.945403  [12864/60000]\n",
      "loss: 1.928551  [19264/60000]\n",
      "loss: 1.792093  [25664/60000]\n",
      "loss: 1.731927  [32064/60000]\n",
      "loss: 1.771696  [38464/60000]\n",
      "loss: 1.937162  [44864/60000]\n",
      "loss: 1.828242  [51264/60000]\n",
      "loss: 1.803262  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.3%, Avg loss: 1.767705 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.760217  [   64/60000]\n",
      "loss: 1.714229  [ 6464/60000]\n",
      "loss: 1.828657  [12864/60000]\n",
      "loss: 1.780590  [19264/60000]\n",
      "loss: 1.632468  [25664/60000]\n",
      "loss: 1.591793  [32064/60000]\n",
      "loss: 1.624379  [38464/60000]\n",
      "loss: 1.804552  [44864/60000]\n",
      "loss: 1.675171  [51264/60000]\n",
      "loss: 1.631787  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 1.611326 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.617029  [   64/60000]\n",
      "loss: 1.567302  [ 6464/60000]\n",
      "loss: 1.666251  [12864/60000]\n",
      "loss: 1.587654  [19264/60000]\n",
      "loss: 1.450141  [25664/60000]\n",
      "loss: 1.432996  [32064/60000]\n",
      "loss: 1.428157  [38464/60000]\n",
      "loss: 1.625238  [44864/60000]\n",
      "loss: 1.485302  [51264/60000]\n",
      "loss: 1.414843  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.417963 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.440794  [   64/60000]\n",
      "loss: 1.383133  [ 6464/60000]\n",
      "loss: 1.457987  [12864/60000]\n",
      "loss: 1.365255  [19264/60000]\n",
      "loss: 1.250646  [25664/60000]\n",
      "loss: 1.255862  [32064/60000]\n",
      "loss: 1.208846  [38464/60000]\n",
      "loss: 1.410017  [44864/60000]\n",
      "loss: 1.286981  [51264/60000]\n",
      "loss: 1.202631  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.218363 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.259036  [   64/60000]\n",
      "loss: 1.184186  [ 6464/60000]\n",
      "loss: 1.245067  [12864/60000]\n",
      "loss: 1.154806  [19264/60000]\n",
      "loss: 1.069167  [25664/60000]\n",
      "loss: 1.085603  [32064/60000]\n",
      "loss: 1.019717  [38464/60000]\n",
      "loss: 1.203280  [44864/60000]\n",
      "loss: 1.109974  [51264/60000]\n",
      "loss: 1.032346  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 1.045591 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.099731  [   64/60000]\n",
      "loss: 1.004447  [ 6464/60000]\n",
      "loss: 1.059469  [12864/60000]\n",
      "loss: 0.981002  [19264/60000]\n",
      "loss: 0.922702  [25664/60000]\n",
      "loss: 0.940773  [32064/60000]\n",
      "loss: 0.874753  [38464/60000]\n",
      "loss: 1.031724  [44864/60000]\n",
      "loss: 0.965777  [51264/60000]\n",
      "loss: 0.903876  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.909373 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.971519  [   64/60000]\n",
      "loss: 0.862865  [ 6464/60000]\n",
      "loss: 0.910282  [12864/60000]\n",
      "loss: 0.849917  [19264/60000]\n",
      "loss: 0.812506  [25664/60000]\n",
      "loss: 0.825486  [32064/60000]\n",
      "loss: 0.766488  [38464/60000]\n",
      "loss: 0.899449  [44864/60000]\n",
      "loss: 0.853206  [51264/60000]\n",
      "loss: 0.809698  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.806856 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.873776  [   64/60000]\n",
      "loss: 0.759348  [ 6464/60000]\n",
      "loss: 0.795714  [12864/60000]\n",
      "loss: 0.756872  [19264/60000]\n",
      "loss: 0.731613  [25664/60000]\n",
      "loss: 0.736978  [32064/60000]\n",
      "loss: 0.684444  [38464/60000]\n",
      "loss: 0.800990  [44864/60000]\n",
      "loss: 0.765939  [51264/60000]\n",
      "loss: 0.741289  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.730097 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.799397  [   64/60000]\n",
      "loss: 0.683436  [ 6464/60000]\n",
      "loss: 0.708853  [12864/60000]\n",
      "loss: 0.691254  [19264/60000]\n",
      "loss: 0.670912  [25664/60000]\n",
      "loss: 0.668991  [32064/60000]\n",
      "loss: 0.619762  [38464/60000]\n",
      "loss: 0.728258  [44864/60000]\n",
      "loss: 0.697191  [51264/60000]\n",
      "loss: 0.690391  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.671110 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.741589  [   64/60000]\n",
      "loss: 0.625895  [ 6464/60000]\n",
      "loss: 0.641973  [12864/60000]\n",
      "loss: 0.643934  [19264/60000]\n",
      "loss: 0.623309  [25664/60000]\n",
      "loss: 0.615921  [32064/60000]\n",
      "loss: 0.566332  [38464/60000]\n",
      "loss: 0.674141  [44864/60000]\n",
      "loss: 0.642297  [51264/60000]\n",
      "loss: 0.651533  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.624166 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.693972  [   64/60000]\n",
      "loss: 0.579904  [ 6464/60000]\n",
      "loss: 0.589062  [12864/60000]\n",
      "loss: 0.608801  [19264/60000]\n",
      "loss: 0.584497  [25664/60000]\n",
      "loss: 0.573874  [32064/60000]\n",
      "loss: 0.520455  [38464/60000]\n",
      "loss: 0.633386  [44864/60000]\n",
      "loss: 0.597992  [51264/60000]\n",
      "loss: 0.620755  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.585594 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.652977  [   64/60000]\n",
      "loss: 0.542041  [ 6464/60000]\n",
      "loss: 0.546334  [12864/60000]\n",
      "loss: 0.581715  [19264/60000]\n",
      "loss: 0.551550  [25664/60000]\n",
      "loss: 0.540057  [32064/60000]\n",
      "loss: 0.480434  [38464/60000]\n",
      "loss: 0.602321  [44864/60000]\n",
      "loss: 0.562070  [51264/60000]\n",
      "loss: 0.595896  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.553176 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.616872  [   64/60000]\n",
      "loss: 0.509977  [ 6464/60000]\n",
      "loss: 0.510722  [12864/60000]\n",
      "loss: 0.559937  [19264/60000]\n",
      "loss: 0.523384  [25664/60000]\n",
      "loss: 0.512539  [32064/60000]\n",
      "loss: 0.445247  [38464/60000]\n",
      "loss: 0.578123  [44864/60000]\n",
      "loss: 0.532487  [51264/60000]\n",
      "loss: 0.575374  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.525565 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.584696  [   64/60000]\n",
      "loss: 0.482588  [ 6464/60000]\n",
      "loss: 0.480661  [12864/60000]\n",
      "loss: 0.541824  [19264/60000]\n",
      "loss: 0.499279  [25664/60000]\n",
      "loss: 0.490066  [32064/60000]\n",
      "loss: 0.414277  [38464/60000]\n",
      "loss: 0.559049  [44864/60000]\n",
      "loss: 0.507854  [51264/60000]\n",
      "loss: 0.558107  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.501844 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.555701  [   64/60000]\n",
      "loss: 0.458971  [ 6464/60000]\n",
      "loss: 0.454878  [12864/60000]\n",
      "loss: 0.526572  [19264/60000]\n",
      "loss: 0.478808  [25664/60000]\n",
      "loss: 0.471756  [32064/60000]\n",
      "loss: 0.387305  [38464/60000]\n",
      "loss: 0.543709  [44864/60000]\n",
      "loss: 0.487177  [51264/60000]\n",
      "loss: 0.543388  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.481387 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.529631  [   64/60000]\n",
      "loss: 0.438410  [ 6464/60000]\n",
      "loss: 0.432742  [12864/60000]\n",
      "loss: 0.513393  [19264/60000]\n",
      "loss: 0.461275  [25664/60000]\n",
      "loss: 0.456704  [32064/60000]\n",
      "loss: 0.364524  [38464/60000]\n",
      "loss: 0.531307  [44864/60000]\n",
      "loss: 0.469606  [51264/60000]\n",
      "loss: 0.530806  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.463706 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.506166  [   64/60000]\n",
      "loss: 0.420722  [ 6464/60000]\n",
      "loss: 0.413536  [12864/60000]\n",
      "loss: 0.501757  [19264/60000]\n",
      "loss: 0.446440  [25664/60000]\n",
      "loss: 0.444271  [32064/60000]\n",
      "loss: 0.344924  [38464/60000]\n",
      "loss: 0.521070  [44864/60000]\n",
      "loss: 0.454689  [51264/60000]\n",
      "loss: 0.519826  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.448408 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.485201  [   64/60000]\n",
      "loss: 0.405324  [ 6464/60000]\n",
      "loss: 0.396629  [12864/60000]\n",
      "loss: 0.491754  [19264/60000]\n",
      "loss: 0.434090  [25664/60000]\n",
      "loss: 0.433860  [32064/60000]\n",
      "loss: 0.328044  [38464/60000]\n",
      "loss: 0.512392  [44864/60000]\n",
      "loss: 0.441665  [51264/60000]\n",
      "loss: 0.510168  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.435130 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.466496  [   64/60000]\n",
      "loss: 0.391808  [ 6464/60000]\n",
      "loss: 0.381715  [12864/60000]\n",
      "loss: 0.482848  [19264/60000]\n",
      "loss: 0.423570  [25664/60000]\n",
      "loss: 0.424808  [32064/60000]\n",
      "loss: 0.313526  [38464/60000]\n",
      "loss: 0.505075  [44864/60000]\n",
      "loss: 0.430186  [51264/60000]\n",
      "loss: 0.501726  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.423552 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.449710  [   64/60000]\n",
      "loss: 0.380104  [ 6464/60000]\n",
      "loss: 0.368413  [12864/60000]\n",
      "loss: 0.474933  [19264/60000]\n",
      "loss: 0.414630  [25664/60000]\n",
      "loss: 0.416938  [32064/60000]\n",
      "loss: 0.301019  [38464/60000]\n",
      "loss: 0.498723  [44864/60000]\n",
      "loss: 0.420076  [51264/60000]\n",
      "loss: 0.494081  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.413400 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4700e-01, -3.6745e+00, -1.5450e+00,  1.2718e-01, -2.8728e+00,\n",
       "          9.6658e-01, -3.2352e+00,  7.0909e+00,  2.5797e+00,  2.1125e+00],\n",
       "        [ 5.0195e-01, -2.4320e+00,  6.0200e+00,  3.2430e+00, -4.7528e+00,\n",
       "          2.2941e+00,  3.8646e+00, -5.1807e+00,  1.7404e+00, -5.6995e+00],\n",
       "        [-5.4105e+00,  5.6299e+00,  1.5015e+00,  2.1017e+00, -2.3074e+00,\n",
       "         -4.1601e-01, -1.1042e+00,  2.5610e-01,  2.2873e+00, -2.4298e-01],\n",
       "        [ 8.9865e+00, -1.4127e+01,  4.8164e-01,  1.3206e+00, -4.1682e+00,\n",
       "          4.4316e+00, -6.1623e-02,  1.4547e-01,  2.8883e+00, -2.2138e+00],\n",
       "        [-5.7682e-01, -6.1576e+00, -7.3567e-02, -3.2124e+00,  4.5325e+00,\n",
       "         -5.9435e-01,  3.6537e-01,  9.4135e-01,  4.2461e-01,  3.7683e+00],\n",
       "        [-7.1220e+00,  7.5146e+00,  1.2673e+00,  3.2336e+00, -3.0438e+00,\n",
       "         -8.0104e-01, -3.0128e+00,  1.3027e+00,  2.9972e+00,  7.2769e-01],\n",
       "        [-3.0319e+00, -4.5748e+00, -5.0801e+00, -1.6865e+00,  5.2630e+00,\n",
       "          2.1273e+00, -1.3166e+00,  1.3037e+00,  7.0504e-01,  4.5406e+00],\n",
       "        [-5.8682e+00,  1.0195e-01, -2.2929e+00,  5.7013e-01,  2.5043e+00,\n",
       "          9.3960e-01, -2.4620e+00,  1.0676e+00,  1.0095e+00,  4.0043e+00],\n",
       "        [ 7.1095e-01, -9.1737e+00,  2.6907e+00, -4.2468e+00,  3.8499e+00,\n",
       "          1.5619e+00,  5.9647e+00, -3.7041e+00,  1.8225e+00, -7.0818e-01],\n",
       "        [-2.5821e+00, -7.8521e+00, -5.7015e+00, -2.7504e+00,  5.4681e+00,\n",
       "          1.0817e+00, -3.3615e+00,  5.8070e+00,  1.6698e+00,  7.7179e+00],\n",
       "        [ 8.4957e+00, -9.8408e+00,  9.5173e-01,  3.0036e+00, -4.2012e+00,\n",
       "          4.7835e+00, -5.4580e-01, -4.1388e+00,  2.3099e+00, -3.7268e+00],\n",
       "        [ 7.4359e-01, -3.6732e+00,  2.3244e+00, -7.9869e-01, -2.3734e-01,\n",
       "          1.2515e+00,  3.5770e+00, -3.1525e+00,  3.0997e+00, -2.5906e+00],\n",
       "        [-2.0552e+00, -6.3756e+00, -3.3009e+00, -1.7361e+00,  4.4948e+00,\n",
       "          4.7848e-01, -3.1864e+00,  3.2940e+00,  8.8272e-01,  6.3842e+00],\n",
       "        [ 8.2271e+00, -1.1523e+01,  1.8086e-01,  4.9415e-01, -3.0615e+00,\n",
       "          3.1931e+00, -2.5369e+00, -1.9450e-01,  3.3231e+00, -4.5965e-01],\n",
       "        [-8.5132e+00,  9.3288e+00,  1.4723e+00,  4.9133e+00, -4.6556e+00,\n",
       "          1.6068e-01, -3.2127e+00,  2.7975e-01,  3.4880e+00, -4.0139e-01],\n",
       "        [ 1.3702e+00, -2.0068e+00, -4.1718e-02,  3.0501e+00, -3.8638e+00,\n",
       "          3.4150e+00, -1.4443e+00, -1.4889e+00,  2.0993e+00, -2.1508e+00],\n",
       "        [-1.3259e+00, -6.2819e+00, -5.9230e-01, -2.5116e+00,  3.6302e+00,\n",
       "         -1.0159e+00, -2.1631e+00,  3.3356e+00,  1.1158e+00,  5.6396e+00],\n",
       "        [ 1.4202e+00, -4.1930e+00, -1.6086e+00,  1.4721e+00, -4.8447e+00,\n",
       "          1.8888e+00, -3.7930e+00,  6.8398e+00,  3.0174e+00,  7.3867e-01],\n",
       "        [-2.4729e+00, -1.4052e+00,  1.3609e+00,  2.4679e+00, -2.7999e+00,\n",
       "          2.7524e+00,  9.3322e-01, -1.6530e+00,  2.1499e+00, -1.9262e+00],\n",
       "        [-1.6529e+00, -5.3595e+00, -2.9650e+00, -1.9879e+00,  6.6743e+00,\n",
       "          6.5732e-01, -4.1804e-01, -6.9998e-01, -6.9013e-01,  4.6048e+00],\n",
       "        [-3.3321e+00, -4.2218e+00, -5.6892e+00,  8.5082e-01,  2.4302e+00,\n",
       "          1.5323e+00, -6.0787e+00,  5.4128e+00,  1.6361e+00,  6.9733e+00],\n",
       "        [-1.0197e+00, -5.3965e+00,  1.2808e+00, -2.2664e+00,  1.8389e+00,\n",
       "          2.8055e+00,  6.3836e+00, -3.5571e+00,  1.9536e+00, -2.6697e+00],\n",
       "        [-2.6891e+00, -2.4984e+00,  1.5657e+00, -3.2455e+00,  3.1057e+00,\n",
       "         -1.0514e+00,  4.2795e+00,  3.4375e-01,  2.0274e+00,  5.7589e-01],\n",
       "        [ 1.7571e+00, -7.1772e+00, -1.3589e+00, -1.3940e-01,  5.8489e-01,\n",
       "          4.3459e+00,  1.6789e+00, -2.5493e+00,  1.4657e+00, -1.2478e+00],\n",
       "        [-1.5095e+00, -4.3478e+00, -1.3924e+00, -1.6424e+00,  4.7037e+00,\n",
       "         -1.9586e-01, -3.9187e-01,  8.9568e-01, -1.0160e+00,  4.0314e+00],\n",
       "        [ 1.3293e+01, -2.2104e+01, -6.8261e-01, -2.4199e+00,  1.1482e+00,\n",
       "          6.3014e+00,  4.6859e+00, -4.6287e+00,  2.8380e+00, -3.1882e+00],\n",
       "        [-1.5002e+00, -2.0264e+00, -1.5995e+00,  3.6299e-01, -1.0416e+00,\n",
       "          3.8272e-01, -2.9169e+00,  5.3411e+00,  1.1700e+00,  2.6755e+00],\n",
       "        [-1.1561e+00, -7.1312e+00, -2.2918e+00, -2.4335e+00,  6.6312e+00,\n",
       "          9.1256e-01, -6.7857e-01, -1.1876e+00,  8.1574e-02,  4.8883e+00],\n",
       "        [ 9.8281e+00, -1.1181e+01,  1.8629e+00,  3.9325e+00, -6.7044e+00,\n",
       "          4.0190e+00, -3.7159e+00, -1.1639e+00,  3.3655e+00, -2.2614e+00],\n",
       "        [-6.0813e+00,  5.1545e+00,  1.3768e-01,  2.3465e+00, -2.3087e+00,\n",
       "          1.2262e+00, -6.8929e-01, -2.2559e-01,  2.6231e+00, -8.0781e-01],\n",
       "        [-2.3983e+00, -3.0592e-01, -2.7178e+00,  6.5267e+00, -5.2500e+00,\n",
       "          4.0180e+00, -6.1926e+00,  2.3446e+00,  1.4826e+00,  1.1129e+00],\n",
       "        [-5.9950e+00,  5.4519e+00, -2.8617e-01,  2.9944e+00, -2.0185e+00,\n",
       "          5.0837e-01, -2.6994e+00,  6.9211e-01,  1.7634e+00,  7.6508e-01],\n",
       "        [-1.8227e+00, -4.4674e-01, -1.6698e+00,  6.1597e+00, -3.4984e+00,\n",
       "          4.8132e+00, -4.4104e+00, -3.2809e+00,  1.5892e+00, -5.8767e-01],\n",
       "        [ 4.1425e+00, -1.0237e+01,  1.3874e+00, -3.5559e+00,  2.9797e+00,\n",
       "          1.5382e+00,  4.7687e+00, -2.5493e+00,  9.8900e-01, -9.9165e-01],\n",
       "        [-2.8507e+00, -1.5685e+00,  1.0851e+00,  1.4544e+00, -3.3972e+00,\n",
       "         -5.9771e-01, -5.4761e+00,  5.8994e+00,  3.0394e+00,  3.8366e+00],\n",
       "        [ 1.8675e-01, -1.7027e+00,  6.6299e+00,  2.9463e+00, -4.8558e+00,\n",
       "          1.1833e+00,  2.2245e+00, -4.0960e+00,  1.6910e+00, -4.2383e+00],\n",
       "        [-1.2162e+00, -3.8610e+00, -2.8674e-01,  2.4315e-01, -2.7791e+00,\n",
       "          8.8951e-01, -2.6765e+00,  5.9147e+00,  2.2457e+00,  2.0432e+00],\n",
       "        [-8.1681e+00,  7.6773e+00, -2.6046e-02,  3.2046e+00, -2.9979e+00,\n",
       "          4.9042e-01, -2.7677e+00,  1.1164e+00,  3.2920e+00,  4.5948e-01],\n",
       "        [-7.2991e-01,  3.9018e-01,  4.6844e+00,  4.1139e+00, -6.2220e+00,\n",
       "          1.8512e+00,  3.4302e-01, -2.2198e+00,  2.2352e+00, -3.9817e+00],\n",
       "        [-7.9611e+00,  8.4558e+00,  1.2924e+00,  4.3042e+00, -4.7700e+00,\n",
       "          6.0647e-01, -2.5755e+00,  8.2039e-02,  4.4279e+00, -9.7266e-01],\n",
       "        [-4.6257e+00,  5.1008e+00,  9.0896e-01,  2.3381e+00, -2.4054e+00,\n",
       "         -3.2834e-02, -1.8686e+00,  2.8816e-01,  1.9526e+00, -1.0057e-01],\n",
       "        [-2.2496e+00, -3.5862e+00, -9.8072e-01, -4.8282e-01, -5.8161e-01,\n",
       "          4.2307e-01, -2.3115e+00,  5.7360e+00,  1.2788e+00,  3.2788e+00],\n",
       "        [-6.3576e+00, -1.1345e+00, -3.2331e+00, -1.6641e+00,  5.9809e+00,\n",
       "         -7.8309e-01, -2.3520e+00,  2.3000e+00,  1.3394e+00,  6.5407e+00],\n",
       "        [-2.4082e+00,  2.4955e+00,  4.6367e+00,  9.7956e-01, -2.2713e+00,\n",
       "         -4.6901e-01,  1.0757e+00, -2.7520e+00,  2.3156e+00, -2.0739e+00],\n",
       "        [-3.2336e+00,  8.0652e-01,  7.4925e-01,  3.7234e+00, -3.1751e+00,\n",
       "          2.5783e+00, -5.5416e-01, -1.2074e+00,  1.2705e+00, -1.4368e+00],\n",
       "        [ 1.8458e+00, -4.4755e+00, -1.7818e+00,  2.6780e+00, -1.6587e+00,\n",
       "          4.7168e+00, -1.2665e+00, -3.3671e+00,  1.9541e+00, -1.6087e+00],\n",
       "        [-7.1908e+00,  4.7278e+00,  5.8420e-01,  4.0937e+00, -2.7505e+00,\n",
       "          1.4338e+00, -2.7171e+00, -2.5922e-01,  1.7351e+00,  6.0566e-01],\n",
       "        [-1.3613e+00, -1.9754e+00,  4.6257e+00, -1.2215e+00,  6.3112e-01,\n",
       "         -7.9007e-01,  3.5516e+00, -2.2845e+00,  5.4717e-01, -1.1135e+00],\n",
       "        [-3.6463e+00, -8.3617e+00, -7.4679e+00, -2.0436e+00,  8.9995e+00,\n",
       "          2.6226e+00, -3.7629e+00,  7.4441e-01,  1.3885e+00,  8.4938e+00],\n",
       "        [-1.1330e+00, -6.5724e+00, -3.9379e-01, -3.6625e+00,  6.3436e+00,\n",
       "         -1.3064e+00,  4.2024e-01,  1.0010e+00, -3.1141e-02,  5.0421e+00],\n",
       "        [ 1.9213e+00, -7.5461e+00,  1.2952e+00, -1.7220e+00,  8.0144e-01,\n",
       "          2.9335e+00,  6.3616e+00, -2.7169e+00,  1.1440e+00, -3.3166e+00],\n",
       "        [-2.4831e-01, -3.3986e+00, -3.4874e-02,  5.7155e+00, -4.1823e+00,\n",
       "          4.0108e+00, -2.9359e+00, -1.6529e+00,  1.4702e+00, -8.2758e-01],\n",
       "        [ 1.9918e+00, -8.3787e+00, -3.8890e+00,  6.7300e-01,  1.5832e+00,\n",
       "          4.8149e+00, -1.1008e+00, -1.2886e+00,  9.0219e-01,  1.0996e+00],\n",
       "        [ 4.2505e-01, -2.6987e+00, -1.7783e+00,  1.7023e+00, -9.0911e-01,\n",
       "          3.2094e+00, -9.5505e-01, -1.3925e+00,  1.2461e+00, -6.9982e-01],\n",
       "        [-9.2779e-01, -3.3698e+00,  4.6420e+00, -1.9139e+00,  1.6382e-01,\n",
       "         -1.3348e-01,  5.3726e+00, -2.5724e+00,  2.4682e+00, -2.4291e+00],\n",
       "        [ 6.9317e+00, -1.0523e+01, -3.6355e-01,  4.9745e-01, -2.9165e+00,\n",
       "          4.1431e+00, -7.6986e-01, -1.0916e+00,  3.4980e+00, -1.7292e+00],\n",
       "        [ 1.8491e-02, -8.9636e+00, -2.1692e+00, -3.4357e+00,  7.1194e+00,\n",
       "          1.4433e+00,  1.2822e+00, -1.9571e+00,  3.3743e-01,  3.8153e+00],\n",
       "        [-5.7315e+00,  6.6513e+00,  1.2666e+00,  3.3583e+00, -3.3762e+00,\n",
       "         -4.0358e-01, -3.1146e+00,  9.1185e-01,  2.4593e+00,  3.1542e-01],\n",
       "        [-1.7105e+00, -6.7670e+00, -3.8263e+00, -1.8687e+00,  5.0899e+00,\n",
       "          8.5021e-02, -3.4544e+00,  4.0080e+00,  6.5951e-01,  7.0767e+00],\n",
       "        [ 1.0663e+00, -4.1031e+00, -1.6639e+00, -4.2780e-01, -1.0930e-01,\n",
       "          2.2072e+00,  1.5978e-02,  1.1221e+00,  1.2044e+00,  3.4504e-02],\n",
       "        [-1.7933e+00, -1.3656e+00, -2.1723e+00,  1.8671e+00, -3.5162e+00,\n",
       "          1.1416e+00, -4.1036e+00,  7.0815e+00,  2.0724e+00,  2.2111e+00],\n",
       "        [-3.4563e-01, -6.0298e+00,  4.1341e+00, -2.3891e+00, -1.2011e+00,\n",
       "          1.2555e+00,  2.5587e+00, -1.7005e+00,  4.6706e+00, -1.1918e+00],\n",
       "        [-1.6276e+00, -4.1684e+00, -3.5897e-01, -1.8029e+00,  3.2974e+00,\n",
       "          6.1636e-01,  6.7234e-01, -4.0449e-01,  3.5357e-01,  2.2739e+00],\n",
       "        [-2.6910e+00,  1.0893e+00,  3.7131e+00,  3.5995e+00, -2.2551e+00,\n",
       "          4.0045e-01, -1.7392e+00, -3.6263e+00,  1.5360e+00, -4.7214e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
